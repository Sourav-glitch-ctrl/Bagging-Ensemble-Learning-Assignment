{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1. **Can we use Bagging for regression problems?**\n",
        "  - Yes, Bagging can be used for regression by averaging predictions from multiple models.\n",
        "\n",
        "2. **Difference between multiple model training and single model training**\n",
        "  - Single model training uses one learner, while multiple model training combines several models to improve performance.\n",
        "\n",
        "3. **Concept of feature randomness in Random Forest**\n",
        "  - Random Forest selects a random subset of features at each split to reduce correlation among trees.\n",
        "\n",
        "4. **What is OOB (Out-of-Bag) Score?**\n",
        "   - OOB score is the accuracy calculated using samples not included in bootstrap training.\n",
        "\n",
        "5. **How to measure feature importance in Random Forest**\n",
        "   - Feature importance is measured by the decrease in impurity or drop in model accuracy when a feature is permuted.\n",
        "\n",
        "6. **Working principle of a Bagging Classifier**\n",
        "   - Bagging trains multiple models on bootstrapped datasets and predicts by majority voting.\n",
        "\n",
        "7. **How do you evaluate a Bagging Classifierâ€™s performance?**\n",
        "  - Using metrics like accuracy, precision, recall, F1-score, or OOB score.\n",
        "\n",
        "8. **How does a Bagging Regressor work?**\n",
        "  - It trains multiple regressors on bootstrapped samples and averages their predictions.\n",
        "\n",
        "9. **Main advantage of ensemble techniques**\n",
        "  - They improve accuracy and reduce overfitting compared to single models.\n",
        "\n",
        "10. **Main challenge of ensemble methods**\n",
        "  -  They increase computational cost and reduce model interpretability.\n",
        "\n",
        "11. **Key idea behind ensemble techniques**\n",
        " -   Combining multiple weak or strong models leads to better overall performance.\n",
        "\n",
        "12. **What is a Random Forest Classifier?**\n",
        "  -  It is an ensemble of decision trees built using bagging and feature randomness.\n",
        "\n",
        "13. **Main types of ensemble techniques**\n",
        "  -  Bagging, Boosting, and Stacking.\n",
        "\n",
        "14. **What is ensemble learning in machine learning?**\n",
        "  -  Ensemble learning combines multiple models to make more accurate predictions.\n",
        "\n",
        "15. **When should we avoid using ensemble methods?**\n",
        " -   When data is small or model simplicity and interpretability are required.\n",
        "\n",
        "16. **How does Bagging help in reducing overfitting?**\n",
        " -   It reduces variance by training models on different bootstrap samples.\n",
        "\n",
        "17. **Why is Random Forest better than a single Decision Tree?**\n",
        "  -  It reduces overfitting and improves accuracy through averaging many trees.\n",
        "\n",
        "18. **Role of bootstrap sampling in Bagging**\n",
        "   - It creates diverse training datasets by sampling with replacement.\n",
        "\n",
        "19. **Real-world applications of ensemble techniques**\n",
        "   - Used in fraud detection, stock prediction, medical diagnosis, and recommendation systems.\n",
        "\n",
        "20. **Difference between Bagging and Boosting**\n",
        "   - Bagging reduces variance using parallel models, while Boosting reduces bias using sequential learning.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1ItvsqjzsG-v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pf7Pk_25jODt",
        "outputId": "84c7ebe8-76bd-477e-b684-aa6a5b92fa21"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "#Q.21) Train a Bagging Classifier using Decision Trees on a sample dataset and print model accuracy.\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "\n",
        "iris = load_iris()\n",
        "df_iris = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "df_iris['target'] = iris.target\n",
        "X = df_iris.drop('target', axis=1)\n",
        "y = df_iris['target']\n",
        "\n",
        "X_train, X_test, y_train, y_test= train_test_split(X,y, test_size=0.3, random_state=42)\n",
        "dt_clf1 = DecisionTreeClassifier()\n",
        "dt_clf2 = DecisionTreeClassifier(max_depth=1)\n",
        "dt_clf3 = DecisionTreeClassifier(max_depth=2)\n",
        "\n",
        "# Corrected: Changed 'estimator' to 'estimators'\n",
        "ensemble_clf= VotingClassifier(estimators=[(\"Decision tree 1\",dt_clf1),(\"Decision tree 2\",dt_clf2 ),('Decision Tree 3',dt_clf3)] )\n",
        "ensemble_clf.fit(X_train,y_train)\n",
        "\n",
        "y_pred= ensemble_clf.predict(X_test)\n",
        "accuracy_score(y_test,y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q.22) Train a Bagging Regressor using Decision Trees and evaluate using Mean Squared Error (MSE).\n",
        "\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import VotingRegressor\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error # Changed accuracy_score to mean_squared_error\n",
        "import pandas as pd\n",
        "\n",
        "iris = load_iris()\n",
        "df_iris = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "df_iris['target'] = iris.target\n",
        "X = df_iris.drop('target', axis=1)\n",
        "y = df_iris['target']\n",
        "\n",
        "X_train, X_test, y_train, y_test= train_test_split(X,y, test_size=0.3, random_state=42)\n",
        "dt_rg1 = DecisionTreeRegressor()\n",
        "dt_rg2 = DecisionTreeRegressor(max_depth=1)\n",
        "dt_rg3 = DecisionTreeRegressor(max_depth=2)\n",
        "\n",
        "# Corrected: Changed 'estimator' to 'estimators'\n",
        "ensemble_clf= VotingRegressor(estimators=[(\"Decision tree 1\",dt_rg1),(\"Decision tree 2\",dt_rg2 ),('Decision Tree 3',dt_rg3)] )\n",
        "ensemble_clf.fit(X_train,y_train)\n",
        "\n",
        "y_pred= ensemble_clf.predict(X_test)\n",
        "print(f\"Mean Squared Error: {mean_squared_error(y_test,y_pred)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHExgkhXzMNp",
        "outputId": "9c53110b-3c5b-463f-8a83-fa229f06b571"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 0.025437968497955626\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q.23 Train a Random Forest Classifier on the Breast Cancer dataset and print feature importance scores.\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "breast_cancer_data = load_breast_cancer()\n",
        "df_bc = pd.DataFrame(breast_cancer_data.data, columns=breast_cancer_data.feature_names)\n",
        "df_bc['target'] = breast_cancer_data.target\n",
        "X= df_bc.drop('target', axis=1)\n",
        "y= df_bc['target']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test= train_test_split(X,y, test_size=0.3, random_state=42)\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "new_rf_clf = RandomForestClassifier()\n",
        "new_rf_clf.fit(X_train,y_train)\n",
        "\n",
        "y_pred= new_rf_clf.predict(X_test)\n",
        "\n",
        "for i,j in zip(breast_cancer_data.feature_names,new_rf_clf.feature_importances_):\n",
        "    print(f'The feature importance of {i} is {j}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "231RShKozMKc",
        "outputId": "45efd743-bf68-43e2-e136-ace575069f21"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The feature importance of mean radius is 0.014401970773632452\n",
            "The feature importance of mean texture is 0.017960446807817977\n",
            "The feature importance of mean perimeter is 0.07419989559498723\n",
            "The feature importance of mean area is 0.05190019944365195\n",
            "The feature importance of mean smoothness is 0.007633147349611119\n",
            "The feature importance of mean compactness is 0.006152319784094225\n",
            "The feature importance of mean concavity is 0.06348858420515548\n",
            "The feature importance of mean concave points is 0.13262333900197237\n",
            "The feature importance of mean symmetry is 0.004371458511905161\n",
            "The feature importance of mean fractal dimension is 0.004723076163976675\n",
            "The feature importance of radius error is 0.010734102908613525\n",
            "The feature importance of texture error is 0.00625631931001833\n",
            "The feature importance of perimeter error is 0.015126135560734945\n",
            "The feature importance of area error is 0.03989412328016241\n",
            "The feature importance of smoothness error is 0.0041150702855448145\n",
            "The feature importance of compactness error is 0.005852492765917422\n",
            "The feature importance of concavity error is 0.006027354634952542\n",
            "The feature importance of concave points error is 0.00300104888956878\n",
            "The feature importance of symmetry error is 0.006011139353373747\n",
            "The feature importance of fractal dimension error is 0.005574380970154619\n",
            "The feature importance of worst radius is 0.08782159173152035\n",
            "The feature importance of worst texture is 0.01652826119384571\n",
            "The feature importance of worst perimeter is 0.10548850205318143\n",
            "The feature importance of worst area is 0.10664661243420168\n",
            "The feature importance of worst smoothness is 0.010466549267220536\n",
            "The feature importance of worst compactness is 0.01684632803212278\n",
            "The feature importance of worst concavity is 0.03850967515849516\n",
            "The feature importance of worst concave points is 0.1190503105197002\n",
            "The feature importance of worst symmetry is 0.009955232252040504\n",
            "The feature importance of worst fractal dimension is 0.008640331761825685\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q.24) Train a Random Forest Regressor and compare its performance with a single Decision Tree.\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error # Changed accuracy_score to mean_squared_error\n",
        "import pandas as pd\n",
        "\n",
        "iris = load_iris()\n",
        "df_iris = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "df_iris['target'] = iris.target\n",
        "X = df_iris.drop('target', axis=1)\n",
        "y = df_iris['target']\n",
        "\n",
        "X_train, X_test, y_train, y_test= train_test_split(X,y, test_size=0.3, random_state=42)\n",
        "dt_rg1 = DecisionTreeRegressor()\n",
        "dt_rg2 = RandomForestRegressor()\n",
        "\n",
        "dt_rg1.fit(X_train,y_train)\n",
        "y1_pred = dt_rg1.predict(X_test)\n",
        "\n",
        "dt_rg2.fit(X_train,y_train)\n",
        "y2_pred = dt_rg2.predict(X_test)\n",
        "\n",
        "print(f\"Mean Squared Error for Decision Tree: {mean_squared_error(y_test,y1_pred)}\")\n",
        "print(f\"Mean Squared Error for Random Forest: {mean_squared_error(y_test,y2_pred)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQ46dqxUzMEW",
        "outputId": "6f7530df-355c-4ce2-9f05-988737b63f9b"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error for Decision Tree: 0.0\n",
            "Mean Squared Error for Random Forest: 0.0012400000000000009\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q.25. Compute the Out-of-Bag (OOB) Score for a Random Forest Classifier.\n",
        "dt_rg2 = RandomForestRegressor(oob_score=True)\n",
        "dt_rg2.fit(X_train,y_train)\n",
        "y2_pred = dt_rg2.predict(X_test)\n",
        "\n",
        "print(f\"Out-of-Bag Score: {dt_rg2.oob_score_}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ofb6W3uOzMBO",
        "outputId": "41eef224-ac4b-4bf1-e010-18d1efc08609"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Out-of-Bag Score: 0.9108105027300227\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q.26.  Train a Bagging Classifier using SVM as a base estimator and print accuracy.\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "\n",
        "iris = load_iris()\n",
        "df_iris = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "df_iris['target'] = iris.target\n",
        "X = df_iris.drop('target', axis=1)\n",
        "y = df_iris['target']\n",
        "\n",
        "X_train, X_test, y_train, y_test= train_test_split(X,y, test_size=0.3, random_state=42)\n",
        "dt_clf1 = SVC(kernel='linear')\n",
        "\n",
        "ensemble_clf= BaggingClassifier(estimator= dt_clf1 )\n",
        "ensemble_clf.fit(X_train,y_train)\n",
        "\n",
        "y_pred= ensemble_clf.predict(X_test)\n",
        "accuracy_score(y_test,y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5o4OT2eQzL98",
        "outputId": "463f0d02-13c9-4342-c9d7-a6fd66993a15"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8d9cdf80",
        "outputId": "932fc870-4c47-4de3-9181-fd1b12dd99cb"
      },
      "source": [
        "#Q.27) Train a Random Forest Classifier with different numbers of trees and compare accuracy.\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "n_estimators_list = [10, 50, 100, 200, 500]\n",
        "\n",
        "for i in n_estimators_list:\n",
        "    rf_clf = RandomForestClassifier(n_estimators=i, random_state=42)\n",
        "    rf_clf.fit(X_train, y_train)\n",
        "    y_pred = rf_clf.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"Accuracy for {i} trees: {accuracy}\")\n"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for 10 trees: 1.0\n",
            "Accuracy for 50 trees: 1.0\n",
            "Accuracy for 100 trees: 1.0\n",
            "Accuracy for 200 trees: 1.0\n",
            "Accuracy for 500 trees: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q.28) Train a Bagging Classifier using Logistic Regression as a base estimator and print AUC score.\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import pandas as pd\n",
        "\n",
        "iris = load_iris()\n",
        "df_iris = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "df_iris['target'] = iris.target\n",
        "X = df_iris.drop('target', axis=1)\n",
        "y = df_iris['target']\n",
        "\n",
        "X_train, X_test, y_train, y_test= train_test_split(X,y, test_size=0.3, random_state=42)\n",
        "dt_clf1 = LogisticRegression(max_iter=1000) # Increased max_iter for convergence if needed\n",
        "\n",
        "ensemble_clf= BaggingClassifier(estimator= dt_clf1 )\n",
        "ensemble_clf.fit(X_train,y_train)\n",
        "\n",
        "y_pred_proba = ensemble_clf.predict_proba(X_test) # Changed to predict_proba\n",
        "print(f\"AUC Score: {roc_auc_score(y_test, y_pred_proba, multi_class='ovr')}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJM-BCJBzL3-",
        "outputId": "87accd2a-807d-48ca-a894-a14b501fc49a"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC Score: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q.29)Train a Random Forest Regressor and analyze feature importance scores\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import pandas as pd\n",
        "\n",
        "dia = load_diabetes()\n",
        "df_dia = pd.DataFrame(dia.data, columns=dia.feature_names)\n",
        "df_dia['target'] = dia.target\n",
        "X7 = df_dia.drop('target', axis=1)\n",
        "y7 = df_dia['target']\n",
        "\n",
        "X7_train, X7_test, y7_train, y7_test= train_test_split(X7,y7, test_size=0.3, random_state=42)\n",
        "dt_rg2 = RandomForestRegressor()\n",
        "\n",
        "\n",
        "dt_rg2.fit(X7_train,y7_train)\n",
        "y7_pred = dt_rg2.predict(X7_test)\n",
        "\n",
        "for i,j in zip(dia.feature_names,dt_rg2.feature_importances_):\n",
        "  print(f\"The feature Importance of {i} is {j}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XuSG3T-PzL1R",
        "outputId": "389d45db-74a4-4368-a97c-621c262f6c2b"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The feature Importance of age is 0.06124425727189294\n",
            "The feature Importance of sex is 0.009846008284236988\n",
            "The feature Importance of bmi is 0.367989592943954\n",
            "The feature Importance of bp is 0.11252410449639302\n",
            "The feature Importance of s1 is 0.05099808950563478\n",
            "The feature Importance of s2 is 0.054166197994537035\n",
            "The feature Importance of s3 is 0.05885136407791225\n",
            "The feature Importance of s4 is 0.031396897379599956\n",
            "The feature Importance of s5 is 0.1890768985017849\n",
            "The feature Importance of s6 is 0.06390658954405419\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q.30) Train an ensemble model using both Bagging and Random Forest and compare accuracy.\n",
        "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "# Load the Titanic dataset\n",
        "data = sns.load_dataset('titanic')\n",
        "data.drop(columns=['deck', 'embark_town'], inplace=True)\n",
        "\n",
        "data['age'].fillna(data['age'].median(), inplace=True)\n",
        "\n",
        "\n",
        "data['embarked'].fillna(data['embarked'].mode()[0], inplace=True)\n",
        "\n",
        "for col in ['adult_male', 'alone']:\n",
        "    data[col] = data[col].astype(int)\n",
        "\n",
        "categorical_features = ['sex', 'embarked', 'class', 'who']\n",
        "data = pd.get_dummies(data, columns=categorical_features, drop_first=True)\n",
        "\n",
        "X = data.drop(columns=['survived', 'alive'])\n",
        "y = data['survived']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize and train models\n",
        "bg_clf = BaggingClassifier(random_state=42)\n",
        "rf_clf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "bg_clf.fit(X_train, y_train)\n",
        "bg_pred = bg_clf.predict(X_test)\n",
        "\n",
        "rf_clf.fit(X_train, y_train)\n",
        "rf_pred = rf_clf.predict(X_test)\n",
        "\n",
        "# Compare accuracy\n",
        "print(f\"Accuracy of Bagging Classifier: {accuracy_score(y_test, bg_pred)}\")\n",
        "print(f\"Accuracy of Random Forest Classifier: {accuracy_score(y_test, rf_pred)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmqbQ3XlyyKx",
        "outputId": "9ca661ad-b774-482e-8970-7250ec84ab00"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3501202249.py:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  data['age'].fillna(data['age'].median(), inplace=True)\n",
            "/tmp/ipython-input-3501202249.py:15: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  data['embarked'].fillna(data['embarked'].mode()[0], inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of Bagging Classifier: 0.7873134328358209\n",
            "Accuracy of Random Forest Classifier: 0.7910447761194029\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Q.31) Train a Random Forest Classifier and tune hyperparameters using GridSearchCV.\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "parameter = {\n",
        "    'n_estimators': [50, 100, 150, 200],\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'max_depth': [ 10, 20, 30]\n",
        "}\n",
        "\n",
        "rf_clf = RandomForestClassifier(random_state=42)\n",
        "grid_search = GridSearchCV(estimator=rf_clf, param_grid=parameter, cv= 5, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "grid_pred = grid_search.predict(X_test)\n",
        "\n",
        "print(f\"Best Parameters: {grid_search.best_params_}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TG1gj1bDyx9u",
        "outputId": "a1051d84-41e0-480d-ecc9-f59c355c6e4e"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'criterion': 'entropy', 'max_depth': 10, 'n_estimators': 100}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q.32) Train a Bagging Regressor with different numbers of base estimators and compare performance.\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.metrics import root_mean_squared_error\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "estimator =  [50, 100, 150, 200]\n",
        "for i in estimator:\n",
        "  bg_rssor = BaggingRegressor(n_estimators=i)\n",
        "  bg_rssor.fit(X_train, y_train)\n",
        "  bg_pred = grid_search.predict(X_test)\n",
        "  print(f\"RMSE of estimator {i} is {root_mean_squared_error(y_test, bg_pred)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMXHeQE9yx6k",
        "outputId": "b736ff93-c331-466c-d2df-158233b4c9b4"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE of estimator 50 is 0.46520738434354325\n",
            "RMSE of estimator 100 is 0.46520738434354325\n",
            "RMSE of estimator 150 is 0.46520738434354325\n",
            "RMSE of estimator 200 is 0.46520738434354325\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q.34: Train a Bagging Classifier and compare its performance with a single Decision Tree Classifier\n",
        "\n",
        "from sklearn.datasets import make_classification\n",
        "X, y = make_classification(n_samples=1000, n_features=20, random_state=42)\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "single_dt = DecisionTreeClassifier()\n",
        "Bagging_clf = BaggingClassifier(estimator=single_dt)\n",
        "Bagging_clf.fit(X_train, y_train)\n",
        "y_pred = Bagging_clf.predict(X_test)\n",
        "print(f\"Accuracy of Bagging Classifier: {accuracy_score(y_test, y_pred)}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "kDfVk3QRyx3q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d33b4e2-929e-4107-a36a-5337954efac8"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of Bagging Classifier: 0.8733333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q.35Train a Random Forest Classifier and visualize the confusion matrix.\n",
        "\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "rf_clf = RandomForestClassifier(random_state=42)\n",
        "rf_clf.fit(X_train, y_train)\n",
        "\n",
        "rf_pred = rf_clf.predict(X_test)\n",
        "c_matrix = confusion_matrix(y_test, rf_pred)\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(c_matrix)\n"
      ],
      "metadata": {
        "id": "B2sFlMDSyxzy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a562b602-2c01-4dd7-e5dc-53ae5707e17e"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[129  16]\n",
            " [ 27 128]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q.37} Train a Random Forest Classifier and print the top 5 most important features\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "data = load_breast_cancer()\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "df['target'] = data.target\n",
        "\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "clf_rf = RandomForestClassifier(random_state=42)\n",
        "clf_rf.fit(X_train, y_train)\n",
        "\n",
        "for i,j in zip(data.feature_names[:5],clf_rf.feature_importances_[:5]):\n",
        "  print(f\"The feature Importance of {i} is {j}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "my2iHoa2CKoa",
        "outputId": "c9ec9d67-f40a-4114-c618-53b64738efca"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The feature Importance of mean radius is 0.032311888273301004\n",
            "The feature Importance of mean texture is 0.011063901250175845\n",
            "The feature Importance of mean perimeter is 0.060092333477412795\n",
            "The feature Importance of mean area is 0.05381045367561502\n",
            "The feature Importance of mean smoothness is 0.006223358550035776\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q.38)Train a Bagging Classifier and evaluate performance using Precision, Recall, and F1-score\n",
        "\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import pandas as pd\n",
        "\n",
        "digits1= load_digits()\n",
        "df_digits1 = pd.DataFrame(digits1.data, columns=digits1.feature_names)\n",
        "df_digits1['target']= digits1.target\n",
        "X= df_digits1.drop('target', axis=1)\n",
        "y= df_digits1['target']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "bagg_clf = BaggingClassifier(random_state=42)\n",
        "bagg_clf.fit(X_train, y_train)\n",
        "bagg_clf_pred = bagg_clf.predict(X_test)\n",
        "\n",
        "precision = precision_score(y_test, bagg_clf_pred, average='weighted')\n",
        "recall = recall_score(y_test, bagg_clf_pred, average='weighted')\n",
        "f1 = f1_score(y_test, bagg_clf_pred, average='weighted')\n",
        "\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-score: {f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcVLBxGCFdws",
        "outputId": "ada8ce1c-15f9-450e-a894-0b2ecdf9e59a"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.9446\n",
            "Recall: 0.9426\n",
            "F1-score: 0.9427\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q.39 Train a Random Forest Classifier and analyze the effect of max_depth on accuracy\n",
        "\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "\n",
        "digits1= load_digits()\n",
        "df_digits1 = pd.DataFrame(digits1.data, columns=digits1.feature_names)\n",
        "df_digits1['target']= digits1.target\n",
        "X= df_digits1.drop('target', axis=1)\n",
        "y= df_digits1['target']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "random_clf1 = RandomForestClassifier(max_depth=1 ,random_state=42)\n",
        "random_clf1.fit(X_train, y_train)\n",
        "random_clf1_pred = bagg_clf.predict(X_test)\n",
        "print(f\"Accuracy when Max Depth is 1: {accuracy_score(y_test, random_clf1_pred)}\")\n",
        "\n",
        "random_clf2 = RandomForestClassifier(max_depth=100 ,random_state=42)\n",
        "random_clf2.fit(X_train, y_train)\n",
        "random_clf2_pred = bagg_clf.predict(X_test)\n",
        "print(f\"Accuracy when Max Depth is 100: {accuracy_score(y_test, random_clf2_pred)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XW79YNToCKlC",
        "outputId": "fbb3ff87-98db-4d7d-ba34-28999465a27a"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy when Max Depth is 1: 0.9425925925925925\n",
            "Accuracy when Max Depth is 100: 0.9425925925925925\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q.41 Train a Random Forest Classifier and evaluate its performance using ROC-AUC Score.\n",
        "\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import pandas as pd\n",
        "\n",
        "digits1= load_digits()\n",
        "df_digits1 = pd.DataFrame(digits1.data, columns=digits1.feature_names)\n",
        "df_digits1['target']= digits1.target\n",
        "X= df_digits1.drop('target', axis=1)\n",
        "y= df_digits1['target']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "\n",
        "random_clf = RandomForestClassifier(max_depth=1 ,random_state=42)\n",
        "random_clf.fit(X_train, y_train)\n",
        "random_clf_pred_proba = random_clf.predict_proba(X_test)\n",
        "print(f\"ROC_AUC_SCORE: {roc_auc_score(y_test, random_clf_pred_proba, multi_class='ovr', average='weighted')}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVwmqZUQCKh4",
        "outputId": "91ab2fc6-de5a-4b03-8243-310d635b9d48"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC_AUC_SCORE: 0.966236963162188\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q.42: Train a Bagging Classifier and evaluate its performance using cross-validation.\n",
        "\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split, cross_val_score # Added cross_val_score\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "import pandas as pd\n",
        "\n",
        "digits1= load_digits()\n",
        "df_digits1 = pd.DataFrame(digits1.data, columns=digits1.feature_names)\n",
        "df_digits1['target']= digits1.target\n",
        "X= df_digits1.drop('target', axis=1)\n",
        "y= df_digits1['target']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "bagg_clf = BaggingClassifier(random_state=42)\n",
        "bagg_clf.fit(X_train, y_train)\n",
        "\n",
        "#Cross Validation\n",
        "cv_scores = cross_val_score(bagg_clf, X, y, cv=5, scoring='accuracy')\n",
        "print(f\"Cross-validation scores: {cv_scores}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PrB2123CKew",
        "outputId": "30194d3b-6087-4d2c-993c-674a4128d8fd"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation scores: [0.875      0.86111111 0.91086351 0.92200557 0.86629526]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Load dataset\n",
        "digits1 = load_digits()\n",
        "df_digits1 = pd.DataFrame(digits1.data)\n",
        "df_digits1['target'] = digits1.target\n",
        "\n",
        "X = df_digits1.drop('target', axis=1)\n",
        "\n",
        "y = (df_digits1['target'] == 1).astype(int)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "random_clf1 = RandomForestClassifier(random_state=42)\n",
        "random_clf1.fit(X_train, y_train)\n",
        "\n",
        "random_clf1_pred = random_clf1.predict_proba(X_test)[:, 1]\n",
        "precision, recall, _ = precision_recall_curve(y_test, random_clf1_pred)\n",
        "\n",
        "plt.plot(recall, precision)\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "5E5SUhS3CKbo",
        "outputId": "21f24cec-e7ba-40cd-e7c2-57106de8726d"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lLOmZ3j2CKYK"
      },
      "execution_count": 72,
      "outputs": []
    }
  ]
}